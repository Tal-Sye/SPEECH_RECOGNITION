# -*- coding: utf-8 -*-
"""Copy of Automatic_Speech_Recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CFsjvg-DjylkyMTHKlv-Ro4AIUVZDr_U
"""

# Change Runtime to GPU T4

# Installation
!pip install --upgrade pip
!pip install --upgrade transformers accelerate
!pip install torchaudio

# Library Import
import torch
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline
from IPython.display import Audio, display
import torchaudio
from transformers import AutoModelForCTC

# Loading the open-source model and creating the ASR pipeline
device = "cuda:0" if torch.cuda.is_available() else "cpu"
torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32

model_id = "facebook/wav2vec2-large-960h-lv60-self"

model = AutoModelForCTC.from_pretrained(model_id)
model.to(device)

processor = AutoProcessor.from_pretrained(model_id)

pipe = pipeline(
    "automatic-speech-recognition",
    model=model,
    tokenizer=processor.tokenizer,
    feature_extractor=processor.feature_extractor,
    device=0 if torch.cuda.is_available() else -1,
)

# Provide the path to the Audio after upload
audio_path = "/content/audio.mp3"

# Play the audio
display(Audio(audio_path, autoplay=True)) # Set autoplay=True to play automatically

# Perform ASR and generate transcription
result = pipe(audio_path)
print("ASR Output:")
print(result["text"])

